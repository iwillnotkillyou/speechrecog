2025-07-29 15:03:14,434 - 2296768032.py - INFO - Feature names: ['hidden-subj-middle', 'hidden-subj-last', 'hidden-cont-middle', 'hidden-cont-last', 'mlp-subj-middle', 'mlp-subj-last', 'mlp-cont-middle', 'mlp-cont-last']
2025-07-29 15:03:14,441 - 2296768032.py - INFO - Number of samples: 904
2025-07-29 15:03:14,454 - 2296768032.py - INFO - Number of samples: 951
2025-07-29 15:03:29,474 - 2440554294.py - INFO - Feature names: ['hidden-subj-middle', 'hidden-subj-last', 'hidden-cont-middle', 'hidden-cont-last', 'mlp-subj-middle', 'mlp-subj-last', 'mlp-cont-middle', 'mlp-cont-last']
2025-07-29 15:03:29,489 - 2440554294.py - INFO - Number of samples: 904
2025-07-29 15:03:29,757 - 2440554294.py - INFO - Number of samples: 951
2025-07-29 15:08:05,140 - 2897826577.py - INFO - Feature names: ['hidden-subj-middle', 'hidden-subj-last', 'hidden-cont-middle', 'hidden-cont-last', 'mlp-subj-middle', 'mlp-subj-last', 'mlp-cont-middle', 'mlp-cont-last']
2025-07-29 15:08:05,153 - 2897826577.py - INFO - Number of samples: 904
2025-07-29 15:08:05,171 - 2897826577.py - INFO - Number of samples: 951
2025-07-29 15:17:54,295 - 332743458.py - INFO - Loading fakepedia...
2025-07-29 15:17:54,582 - 332743458.py - INFO - Loading model...
2025-07-29 15:17:58,808 - modeling.py - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-07-29 15:18:01,420 - 332743458.py - INFO - Starting causal tracing...
2025-07-29 15:18:03,198 - 3170854711.py - INFO - Found 0 unfaithful facts and 21 grounded facts
2025-07-29 15:18:04,906 - 3170854711.py - INFO - Running causal tracing on 10 grounded facts
2025-07-29 15:18:27,457 - 3340494713.py - INFO - Output data saved in the following location due to an exception: runs/2025-07-27_14-57-18/grounded.json
2025-07-29 15:18:31,495 - 332743458.py - INFO - Loading fakepedia...
2025-07-29 15:18:31,621 - 332743458.py - INFO - Loading model...
2025-07-29 15:18:31,919 - modeling.py - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-07-29 15:18:33,149 - 332743458.py - INFO - Starting causal tracing...
2025-07-29 15:18:34,746 - 3170854711.py - INFO - Found 0 unfaithful facts and 21 grounded facts
2025-07-29 15:18:36,180 - 3170854711.py - INFO - Running causal tracing on 10 grounded facts
2025-07-29 15:18:36,206 - 3340494713.py - INFO - Loaded 0 previously computed entries from the data stored in runs/2025-07-27_14-57-18/grounded.json.
2025-07-29 15:45:21,731 - 3340494713.py - INFO - Output data saved in the following location: runs/2025-07-27_14-57-18/grounded.json
2025-07-29 15:45:21,778 - 3170854711.py - INFO - Running causal tracing on 0 unfaithful facts
2025-07-29 15:45:21,824 - 3340494713.py - INFO - Output data saved in the following location: runs/2025-07-27_14-57-18/unfaithful.json
